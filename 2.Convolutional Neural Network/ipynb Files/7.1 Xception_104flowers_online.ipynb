{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58deb6f-31cb-4e0b-8b10-a2858eb2aa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os,math,re,sys\n",
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" #CPU Only\n",
    "\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'#GPU Running\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05f4dd0-6b2b-4ad2-8816-e6f162cf1c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(devices=None) #Use all available GPUs or CPU\n",
    "print(\"REPLICAS:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae0fa657-d7e0-49a5-a525-8a64255eb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = [512,512]\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 13\n",
    "\n",
    "LR_START = 0.001\n",
    "LR_MAX = 0.01 * strategy.num_replicas_in_sync\n",
    "LR_MIN = 0.001\n",
    "LR_RAMPUP_EPOCHS = 0\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "LR_EXP_DECAY = .93\n",
    "\n",
    "def scheduler_epoch(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        learning_rate = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        learning_rate = LR_MAX\n",
    "    else:\n",
    "        learning_rate = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return learning_rate\n",
    "                \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cb0d39b-43cb-4470-85e8-255aa4738f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet_Path = '/104_Flowers'\n",
    "Train_Size_Choice = {\n",
    "    192: DataSet_Path + '/jpeg-192x192_train.tfrecord',\n",
    "    224: DataSet_Path + '/jpeg-224x224_train.tfrecord',\n",
    "    311: DataSet_Path + '/jpeg-311x311_train.tfrecord',\n",
    "    512: DataSet_Path + '/jpeg-512x512_train.tfrecord'\n",
    "}\n",
    "\n",
    "Val_Size_Choice = {\n",
    "    192: DataSet_Path + '/jpeg-192x192_val.tfrecord',\n",
    "    224: DataSet_Path + '/jpeg-224x224_val.tfrecord',\n",
    "    311: DataSet_Path + '/jpeg-311x311_val.tfrecord',\n",
    "    512: DataSet_Path + '/jpeg-512x512_val.tfrecord'\n",
    "}\n",
    "\n",
    "TrainSet_Path = Train_Size_Choice[IMG_SIZE[0]]\n",
    "ValSet_Path = Val_Size_Choice[IMG_SIZE[0]]\n",
    "\n",
    "CLASS = ['toad lily', 'love in the mist', 'monkshood', 'azalea', 'fritillary', \n",
    "         'silverbush', 'canterbury bells', 'stemless gentian', 'pink primrose', 'buttercup', \n",
    "         'poinsettia', 'desert-rose', 'bird of paradise', 'columbine', 'frangipani', \n",
    "         'sweet pea', 'siam tulip', 'great masterwort', 'hard-leaved pocket orchid', 'marigold', \n",
    "         'foxglove', 'wild pansy', 'windflower', 'daisy', 'tiger lily', \n",
    "         'purple coneflower', 'orange dahlia', 'globe-flower', 'lilac hibiscus', 'fire lily', \n",
    "         'balloon flower', 'iris', 'bishop of llandaff', 'yellow iris', 'garden phlox', \n",
    "         'alpine sea holly', 'geranium', 'pink quill', 'tree poppy', 'spear thistle', \n",
    "         'bromelia', 'common dandelion', 'sword lily', 'peruvian lily', 'carnation', \n",
    "         'cosmos', 'spring crocus', 'lotus', 'bolero deep blue', 'anthurium', \n",
    "         'rose', 'water lily', 'primula', 'blackberry lily', 'gaura', \n",
    "         'trumpet creeper', 'globe thistle', 'sweet william', 'snapdragon', 'mexican petunia', \n",
    "         'cyclamen ', 'petunia', 'gazania', 'king protea', 'blanket flower', \n",
    "         'common tulip', 'giant white arum lily', 'wild rose', 'morning glory', 'thorn apple', \n",
    "         'pincushion flower', 'tree mallow', 'canna lily', 'camellia', 'pink-yellow dahlia', \n",
    "         'bee balm', 'wild geranium', 'artichoke', 'black-eyed susan', 'ruby-lipped cattleya', \n",
    "         'clematis', 'prince of wales feathers', 'hibiscus', 'cautleya spicata', 'lenten rose', \n",
    "         'red ginger', \"colt's foot\", 'hippeastrum ', 'mallow', 'californian poppy', \n",
    "         'corn poppy', 'moon orchid', 'passion flower', 'grape hyacinth', 'japanese anemone', \n",
    "         'watercress', 'cape flower', 'osteospermum', 'barberton daisy', 'bougainvillea', \n",
    "         'magnolia', 'sunflower', 'daffodil', 'wallflower']\n",
    "\n",
    "NUM_TRAINING_IMG = 12753\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMG // BATCH_SIZE\n",
    "NUM_VALIDATION_IMG = 3712\n",
    "VALIDATION_STEPS = -(-NUM_VALIDATION_IMG // BATCH_SIZE) #The \"-(- // )\" trick rounds up instead of down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e738cbc-e10a-46d7-9efd-8ee46a89f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3) #JPEG --> Tensor\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    #image = tf.reshape(image, [*IMG_SIZE, 3])\n",
    "    image = tf.image.resize(image, IMG_SIZE) #image must be 3-D, so resize it\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    image_feature_dict = {\n",
    "        'image': tf.io.FixedLenFeature([],tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_id': tf.io.FixedLenFeature([],tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, image_feature_dict) #return a dict\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['label'], tf.int64) #104 classes in[0,103]\n",
    "    image_id = example['image_id'] \n",
    "    return image,label   #return a tuple\n",
    "\n",
    "def load_dataset(filenames, ordered = False):\n",
    "    ignore_order = tf.data.Options()\n",
    "\n",
    "    if not ordered:\n",
    "        ignore_order.deterministic = False # experimental_deterministic has been baned\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "    return dataset\n",
    "\n",
    "def data_augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label\n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TrainSet_Path) #ordered default is False\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) #Prepare later elements\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered = False):\n",
    "    dataset = load_dataset(ValSet_Path, ordered = ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    #dataset = dataset.cache() #cache files in memory  Might lead to session die\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da274ff5-8afd-46d4-8ee0-450d985f8648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "(16, 512, 512, 3) (16,)\n",
      "(16, 512, 512, 3) (16,)\n",
      "(16, 512, 512, 3) (16,)\n",
      "Training label examples: [ 67  58  13   5  31  67  69  23  76   3  50  65 103  20  87  22]\n",
      "67 <class 'numpy.int64'>\n",
      "[[[0.21960786 0.3019608  0.08235294]\n",
      "  [0.21568629 0.29803923 0.07843138]\n",
      "  [0.20392159 0.29411766 0.08235294]\n",
      "  ...\n",
      "  [0.23529413 0.40784317 0.1764706 ]\n",
      "  [0.21568629 0.3921569  0.1764706 ]\n",
      "  [0.21568629 0.3921569  0.1764706 ]]\n",
      "\n",
      " [[0.21960786 0.3019608  0.08235294]\n",
      "  [0.21568629 0.29803923 0.07843138]\n",
      "  [0.20392159 0.29411766 0.08235294]\n",
      "  ...\n",
      "  [0.23137257 0.4039216  0.17254902]\n",
      "  [0.21568629 0.3921569  0.16862746]\n",
      "  [0.21568629 0.3921569  0.1764706 ]]\n",
      "\n",
      " [[0.21960786 0.29803923 0.09019608]\n",
      "  [0.21568629 0.29411766 0.08627451]\n",
      "  [0.20392159 0.29411766 0.09019608]\n",
      "  ...\n",
      "  [0.22352943 0.39607847 0.16470589]\n",
      "  [0.21568629 0.3921569  0.16862746]\n",
      "  [0.21960786 0.39607847 0.17254902]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.09019608 0.14117648 0.0627451 ]\n",
      "  [0.09019608 0.14117648 0.0627451 ]\n",
      "  [0.09019608 0.14117648 0.0627451 ]\n",
      "  ...\n",
      "  [0.34509805 0.47450984 0.30588236]\n",
      "  [0.34509805 0.47450984 0.30588236]\n",
      "  [0.34901962 0.4784314  0.30980393]]\n",
      "\n",
      " [[0.09019608 0.14117648 0.0627451 ]\n",
      "  [0.09019608 0.14117648 0.0627451 ]\n",
      "  [0.09019608 0.14117648 0.0627451 ]\n",
      "  ...\n",
      "  [0.34509805 0.47450984 0.30588236]\n",
      "  [0.34901962 0.4784314  0.30980393]\n",
      "  [0.34901962 0.4784314  0.30980393]]\n",
      "\n",
      " [[0.09019608 0.14117648 0.0627451 ]\n",
      "  [0.09019608 0.14117648 0.0627451 ]\n",
      "  [0.09019608 0.14117648 0.0627451 ]\n",
      "  ...\n",
      "  [0.34901962 0.4784314  0.30980393]\n",
      "  [0.34901962 0.4784314  0.30980393]\n",
      "  [0.3529412  0.48235297 0.3137255 ]]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shapes:\")\n",
    "for image, label in get_training_dataset().take(3):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "print(\"Training label examples:\", label.numpy())\n",
    "labelarray = label.numpy()\n",
    "print(labelarray[0],type(labelarray[0]))\n",
    "imagearray = image.numpy()\n",
    "print(imagearray[0], type(imagearray[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5698c4f0-114f-4456-b17b-37d55bd54c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda_2 (Lambda)           (None, 512, 512, 3)       0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, None, None, 2048)  20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flower_prob (Dense)         (None, 104)               213096    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,074,576\n",
      "Trainable params: 21,020,048\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    pretrained_model = tf.keras.applications.Xception(weights=None, include_top=False)\n",
    "        \n",
    "    model = tf.keras.Sequential([\n",
    "        # convert image format from int [0,255] to the format expected by this model\n",
    "        tf.keras.layers.Lambda(lambda data: tf.keras.applications.xception.preprocess_input(tf.cast(data, tf.float32)), input_shape=[*IMG_SIZE, 3]),\n",
    "        pretrained_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(len(CLASS), activation='softmax', name='flower_prob')\n",
    "    ])\n",
    "    \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    "    steps_per_execution=1\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59f972c9-837e-4f82-9b83-960ee0a0d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.010000000000000002.\n",
      "Epoch 1/13\n",
      "797/797 [==============================] - 461s 563ms/step - loss: 4.0712 - sparse_categorical_accuracy: 0.1021 - val_loss: 1356.3435 - val_sparse_categorical_accuracy: 0.0552 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.00937.\n",
      "Epoch 2/13\n",
      "797/797 [==============================] - 452s 567ms/step - loss: 3.3283 - sparse_categorical_accuracy: 0.1640 - val_loss: 346.8355 - val_sparse_categorical_accuracy: 0.0100 - lr: 0.0088\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.008239213000000002.\n",
      "Epoch 4/13\n",
      "797/797 [==============================] - 447s 561ms/step - loss: 3.1482 - sparse_categorical_accuracy: 0.2017 - val_loss: 138.3757 - val_sparse_categorical_accuracy: 0.0361 - lr: 0.0082\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.007732468090000002.\n",
      "Epoch 5/13\n",
      "797/797 [==============================] - 450s 564ms/step - loss: 2.9443 - sparse_categorical_accuracy: 0.2411 - val_loss: 272.1664 - val_sparse_categorical_accuracy: 0.0156 - lr: 0.0077\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.007261195323700002.\n",
      "Epoch 6/13\n",
      "797/797 [==============================] - 447s 561ms/step - loss: 2.7817 - sparse_categorical_accuracy: 0.2774 - val_loss: 121.0146 - val_sparse_categorical_accuracy: 0.0240 - lr: 0.0073\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0068229116510410024.\n",
      "Epoch 7/13\n",
      "797/797 [==============================] - 443s 556ms/step - loss: 2.5890 - sparse_categorical_accuracy: 0.3145 - val_loss: 702.3513 - val_sparse_categorical_accuracy: 0.0100 - lr: 0.0068\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.006415307835468133.\n",
      "Epoch 8/13\n",
      "797/797 [==============================] - 451s 566ms/step - loss: 2.4406 - sparse_categorical_accuracy: 0.3566 - val_loss: 492.7601 - val_sparse_categorical_accuracy: 0.0240 - lr: 0.0064\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.006036236286985364.\n",
      "Epoch 9/13\n",
      "797/797 [==============================] - 448s 562ms/step - loss: 2.2732 - sparse_categorical_accuracy: 0.3964 - val_loss: 349.9734 - val_sparse_categorical_accuracy: 0.0240 - lr: 0.0060\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.005683699746896389.\n",
      "Epoch 10/13\n",
      "797/797 [==============================] - 447s 561ms/step - loss: 2.0964 - sparse_categorical_accuracy: 0.4415 - val_loss: 500.5863 - val_sparse_categorical_accuracy: 0.0043 - lr: 0.0057\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.005355840764613641.\n",
      "Epoch 11/13\n",
      "797/797 [==============================] - 446s 560ms/step - loss: 1.9332 - sparse_categorical_accuracy: 0.4804 - val_loss: 323.6049 - val_sparse_categorical_accuracy: 0.0442 - lr: 0.0054\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.005050931911090687.\n",
      "Epoch 12/13\n",
      "797/797 [==============================] - 448s 562ms/step - loss: 1.7891 - sparse_categorical_accuracy: 0.5175 - val_loss: 99.3766 - val_sparse_categorical_accuracy: 0.0361 - lr: 0.0051\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.004767366677314339.\n",
      "Epoch 13/13\n",
      "797/797 [==============================] - 445s 558ms/step - loss: 1.6131 - sparse_categorical_accuracy: 0.5612 - val_loss: 913.5253 - val_sparse_categorical_accuracy: 0.0442 - lr: 0.0048\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(get_training_dataset(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS,\n",
    "                    validation_data=get_validation_dataset(), validation_steps=VALIDATION_STEPS,\n",
    "                    callbacks=[lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8005f8f-47f2-488e-9fb6-7bd4fce025e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(training, validation, title, subplot, zoom_pcent=None, ylim=None):\n",
    "    # zoom_pcent: X autoscales y axis for the last X% of data points\n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation, '--')\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    if zoom_pcent is not None:\n",
    "        ylen = len(training)*(100-zoom_pcent)//100\n",
    "        ymin = min([min(training[ylen:]), min(validation[ylen:])])\n",
    "        ymax = max([max(training[ylen:]), max(validation[ylen:])])\n",
    "        ax.set_ylim([ymin-(ymax-ymin)/20, ymax+(ymax-ymin)/20])\n",
    "    if ylim is not None:\n",
    "        ymin = ylim[0]\n",
    "        ymax = ylim[1]\n",
    "        ax.set_ylim([ymin-(ymax-ymin)/20, ymax+(ymax-ymin)/20])\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])\n",
    "    \n",
    "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211, ylim=[0,2.5])\n",
    "display_training_curves(history.history['sparse_categorical_accuracy'], history.history['val_sparse_categorical_accuracy'], 'accuracy', 212)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1b505-75ce-433d-8819-534d7bf9f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdataset = get_validation_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n",
    "images_ds = cmdataset.map(lambda image, label: image)\n",
    "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
    "cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMG))).numpy() # get everything as one batch\n",
    "cm_probabilities = model.predict(images_ds, steps=VALIDATION_STEPS)\n",
    "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
    "print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n",
    "print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f55f5-ca72-4cb6-a495-808449753369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(cmat, score, precision, recall):\n",
    "    plt.figure(figsize=(25,25))\n",
    "    ax = plt.gca()\n",
    "    ax.matshow(cmat, cmap='Reds')\n",
    "    ax.set_xticks(range(len(CLASS)))\n",
    "    ax.set_xticklabels(CLASS)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
    "    ax.set_yticks(range(len(CLASS)))\n",
    "    ax.set_yticklabels(CLASS)\n",
    "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    #titlestring = \"\"\n",
    "    #if score is not None:\n",
    "    #    titlestring += 'f1 = {:.3f} '.format(score)\n",
    "    #if precision is not None:\n",
    "    #    titlestring += '\\nprecision = {:.3f} '.format(precision)\n",
    "    #if recall is not None:\n",
    "    #    titlestring += '\\nrecall = {:.3f} '.format(recall)\n",
    "    #if len(titlestring) > 0:\n",
    "    #    ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n",
    "    plt.show()\n",
    "    \n",
    "cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASS)))\n",
    "score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASS)), average='macro')\n",
    "precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASS)), average='macro')\n",
    "recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASS)), average='macro')\n",
    "cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\n",
    "display_confusion_matrix(cmat, score, precision, recall)\n",
    "print('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
