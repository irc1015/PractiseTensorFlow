{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d905c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib\n",
    "import matplotlib.pylab as plt\n",
    "import csv\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "reshape_dims = [IMG_HEIGHT,IMG_WIDTH]\n",
    "\n",
    "CLASS_NAMES = ['roses', 'sunflowers', 'daisy', 'dandelion', 'tulips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebace97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(filename, reshape_dims):\n",
    "  # 1.Read the file\n",
    "  img = tf.io.read_file(filename)\n",
    "\n",
    "  # 2.Convert the compressed string to a 3D uint8 tensor.\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "\n",
    "  # 3.Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "  # 4.Resize the image to the desired size.\n",
    "  return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "def decode_csv(csv_row):\n",
    "  record_defaults = [\"path\", \"flower\"]\n",
    "  rowpath, label_string = tf.io.decode_csv(csv_row,record_defaults)\n",
    "  img = read_and_decode(rowpath,reshape_dims)\n",
    "  #label = tf.math.equal(CLASS_NAMES, label_string)\n",
    "  return img, label_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edae36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Centroid:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        self.sum_so_far = tf.constant(0., dtype=tf.float32)\n",
    "        self.count_so_far = 0\n",
    "\n",
    "    def update(self, value):\n",
    "        self.sum_so_far = self.sum_so_far + value\n",
    "        self.count_so_far = self.count_so_far + 1\n",
    "        if self.count_so_far % 100 == 0:\n",
    "            print(self.label, self.count_so_far)\n",
    "\n",
    "    def centroid(self):\n",
    "        return self.sum_so_far / self.count_so_far\n",
    "\n",
    "    def __str__(self):\n",
    "        return '{} {}'.format(self.label, self.centroid().numpy())\n",
    "\n",
    "\n",
    "class CentroidRule:\n",
    "    def __init__(self):\n",
    "        self.centroids = {\n",
    "            f: Centroid(f) for f in CLASS_NAMES}\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        for img, label in dataset:\n",
    "            label = label.numpy().decode(\"utf-8\")\n",
    "            avg = tf.reduce_mean(img, axis=[0, 1])  # average pixel in the image\n",
    "            self.centroids[label].update(avg)\n",
    "\n",
    "    def predict(self, img):\n",
    "        avg = tf.reduce_mean(img, axis=[0, 1])  # average pixel in the image\n",
    "        best_label = \"\"\n",
    "        best_diff = 999\n",
    "        for key, val in self.centroids.items():\n",
    "            diff = tf.reduce_sum(tf.abs(avg - val.centroid()))\n",
    "            if diff < best_diff:\n",
    "                best_diff = best_diff\n",
    "                best_label = key\n",
    "        return best_label\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        num_correct, total_images = 0, 0\n",
    "        for img, label in dataset:\n",
    "            correct = label.numpy().decode('utf-8')\n",
    "            predicted = self.predict(img)\n",
    "            if correct == predicted:\n",
    "                num_correct = num_correct + 1\n",
    "            total_images = total_images + 1\n",
    "        accuracy = num_correct / total_images\n",
    "        return (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c388ced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roses 100\n",
      "roses 200\n",
      "roses 300\n",
      "roses 400\n",
      "roses 500\n",
      "sunflowers 100\n",
      "sunflowers 200\n",
      "sunflowers 300\n",
      "sunflowers 400\n",
      "sunflowers 500\n",
      "sunflowers 600\n",
      "daisy 100\n",
      "daisy 200\n",
      "daisy 300\n",
      "daisy 400\n",
      "daisy 500\n",
      "dandelion 100\n",
      "dandelion 200\n",
      "dandelion 300\n",
      "dandelion 400\n",
      "dandelion 500\n",
      "dandelion 600\n",
      "dandelion 700\n",
      "dandelion 800\n",
      "tulips 100\n",
      "tulips 200\n",
      "tulips 300\n",
      "tulips 400\n",
      "tulips 500\n",
      "tulips 600\n",
      "tulips 700\n",
      "daisy [0.42736965 0.4373861  0.33928064]\n",
      "roses [0.4905707 0.3742271 0.3220603]\n",
      "sunflowers [0.4931727  0.4762107  0.26768953]\n",
      "dandelion [0.41838878 0.4306628  0.2762968 ]\n",
      "tulips [0.4819211 0.3998665 0.3025558]\n",
      "0.21680216802168023\n"
     ]
    }
   ],
   "source": [
    "rule = CentroidRule()\n",
    "\n",
    "train_dataset = (tf.data.TextLineDataset('/Users/zhuzhirui/.keras/datasets/flower_photos/train_set.csv')\n",
    "                 .map(decode_csv))\n",
    "\n",
    "eval_dataset = (tf.data.TextLineDataset(\"/Users/zhuzhirui/.keras/datasets/flower_photos/eval_set.csv\")\n",
    "                .map(decode_csv))\n",
    "\n",
    "rule.fit(train_dataset)\n",
    "\n",
    "print(rule.centroids['daisy'])\n",
    "print(rule.centroids['roses'])\n",
    "print(rule.centroids['sunflowers'])\n",
    "print(rule.centroids['dandelion'])\n",
    "print(rule.centroids['tulips'])\n",
    "\n",
    "print(rule.evaluate(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53864fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tulips\n"
     ]
    }
   ],
   "source": [
    "#How to predict a sample\n",
    "#/Users/zhuzhirui/.keras/datasets/flower_photos/roses/3145692843_d46ba4703c.jpg,roses\n",
    "filepath = '/Users/zhuzhirui/.keras/datasets/flower_photos/roses/3145692843_d46ba4703c.jpg'\n",
    "img = read_and_decode(filepath,[IMG_HEIGHT,IMG_WIDTH])\n",
    "pred = rule.predict(img)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d905ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
